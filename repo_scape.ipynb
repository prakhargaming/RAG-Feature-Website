{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "18cb480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pymongo\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "\n",
    "from typing import TypedDict\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from dotenv import load_dotenv\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e25bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_client = genai.Client(api_key=os.getenv(\"GEMINI\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb050bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = os.getenv(\"MONGODB_URI\")\n",
    "mongo_client = pymongo.MongoClient(uri, server_api=pymongo.server_api.ServerApi(\n",
    "   version=\"1\", strict=True, deprecation_errors=True))\n",
    "\n",
    "Prakharbase = mongo_client[\"Prakharbase\"]\n",
    "vector_database = Prakharbase[\"vector_database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9694c420",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = \"prakhargaming\"\n",
    "GITHUB_TOKEN = os.getenv(\"REPO\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f5e06c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class __repo_old:\n",
    "    def __init__(self, name, url, languages, topics, readme):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.languages = languages\n",
    "        self.topics = topics\n",
    "        self.readme = readme\n",
    "\n",
    "class repo(TypedDict):\n",
    "    name: str\n",
    "    url: str\n",
    "    languages: dict[str, int]\n",
    "    topics: list[str]\n",
    "    readme: str\n",
    "    embedding: list[float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e83e8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = \"prakhargaming\"\n",
    "GITHUB_TOKEN = os.getenv(\"REPO\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b2fe8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_desc(name=\"\", url=\"\", languages=\"\", tags=\"\", readme=\"\"):\n",
    "    return f\"\"\"\n",
    "# METADATA\n",
    "Repository name: {name}\n",
    "Repository URL: {url}\n",
    "Repository languages: {languages}\n",
    "Repository topics: {tags}\n",
    "\n",
    "# README:\n",
    "{readme}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf725a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_tag(readme_text, languages) -> list[str]:\n",
    "    tags = []\n",
    "\n",
    "    # Keywords for different skill areas\n",
    "    computer_vision_keywords = [\"opencv\", \"cnn\", \"image\", \"vision\", \"detection\", \"segmentation\", \"recognition\"]\n",
    "    nlp_keywords = [\"bert\", \"transformer\", \"token\", \"nlp\", \"text classification\", \"language model\"]\n",
    "    web_dev_keywords = [\"react\", \"flask\", \"django\", \"express\", \"api\", \"frontend\", \"backend\", \"web app\"]\n",
    "    data_science_keywords = [\"pandas\", \"numpy\", \"dataframe\", \"analysis\", \"plot\", \"visualization\"]\n",
    "    ai_keywords = [\"deep learning\", \"machine learning\", \"reinforcement learning\", \"model\", \"training\"]\n",
    "\n",
    "    text = readme_text.lower()\n",
    "\n",
    "    # Helper function\n",
    "    def contains_any(keywords):\n",
    "        return any(keyword in text for keyword in keywords)\n",
    "\n",
    "    # Tagging based on content\n",
    "    if contains_any(computer_vision_keywords) or 'OpenCV' in languages:\n",
    "        tags.append(\"computer-vision\")\n",
    "    if contains_any(nlp_keywords):\n",
    "        tags.append(\"nlp\")\n",
    "    if contains_any(web_dev_keywords):\n",
    "        tags.append(\"web-development\")\n",
    "    if contains_any(data_science_keywords):\n",
    "        tags.append(\"data-science\")\n",
    "    if contains_any(ai_keywords):\n",
    "        tags.append(\"artificial-intelligence\")\n",
    "\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1e1c166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_public_repo_information(username: str, generate_embeddings=False, generate_files=False) -> dict[str, repo]:\n",
    "    repo_url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    request_repo = requests.get(repo_url, headers=headers)\n",
    "    if request_repo.status_code != 200:\n",
    "        print(f\"Request Failed (request_repo): {request_repo.status_code} \\n {repo_url}\")\n",
    "        return request_repo.status_code\n",
    "    data = request_repo.json()\n",
    "    repo_info = []\n",
    "    if generate_files:\n",
    "        directory = \"github_repos_info\"\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "    for repos in data:\n",
    "        repo_name = repos[\"name\"]\n",
    "        repo_url = repos[\"url\"]\n",
    "        language_url = f\"https://api.github.com/repos/{username}/{repo_name}/languages\"\n",
    "        readme_url = f\"https://api.github.com/repos/{username}/{repo_name}/readme\"\n",
    "\n",
    "        request_languages = requests.get(language_url, headers=headers)\n",
    "        if request_languages.status_code == 200:     \n",
    "            repo_languages = request_languages.json()\n",
    "        else:\n",
    "            print(f\"Request Failed (request_languages): {request_languages.status_code} \\n {language_url}\")\n",
    "            repo_languages = {}\n",
    "\n",
    "        request_readme = requests.get(readme_url, headers=headers)\n",
    "        if request_readme.status_code == 200:\n",
    "            readme_content = request_readme.json()\n",
    "            repo_readme = base64.b64decode(readme_content[\"content\"]).decode('utf-8')\n",
    "        else:\n",
    "            print(f\"Request Failed (request_readme): {request_readme.status_code} \\n {readme_url}\")\n",
    "            repo_readme = \"\"\n",
    "        \n",
    "        repo_tags = auto_tag(repo_readme, repo_languages)\n",
    "        \n",
    "        if generate_embeddings:\n",
    "            to_embed = generate_desc(repo_name, repo_url, repo_languages, repo_tags, repo_readme)\n",
    "            result = google_client.models.embed_content(\n",
    "                model=\"text-embedding-004\",\n",
    "                contents=to_embed,\n",
    "                config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")\n",
    "            )\n",
    "            repo_embedding = result.embeddings[0].values\n",
    "        else:\n",
    "            repo_embedding = []\n",
    "\n",
    "        if generate_files:\n",
    "            file_path = f\"github_repos_info\\\\REPO_INFO_{repo_name}.txt\"\n",
    "            file_contents = generate_desc(repo_name, repo_url, repo_languages, repo_tags, repo_readme)\n",
    "            try:\n",
    "                with open(file_path, \"w\") as file:\n",
    "                    file.write(file_contents)\n",
    "                print(f\"File '{file_path}' created successfully.\")\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "\n",
    "        repo_info.append(\n",
    "            repo(\n",
    "                name=repo_name,\n",
    "                url=repo_url,\n",
    "                languages=repo_languages,\n",
    "                topics=auto_tag(repo_readme, repo_languages),\n",
    "                readme=repo_readme,\n",
    "                embedding=repo_embedding\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return repo_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7c5b6bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request Failed (request_readme): 404 \n",
      " https://api.github.com/repos/prakhargaming/amazonInterview/readme\n",
      "File 'github_repos_info\\REPO_INFO_amazonInterview.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_Data-Visualization-Web-Dev-Project.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_FastSAM-needle-biopsy.txt' created successfully.\n",
      "An error occurred: 'charmap' codec can't encode character '\\u0259' in position 1143: character maps to <undefined>\n",
      "File 'github_repos_info\\REPO_INFO_flask-react-template.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_GenAI_Catagorization_Engine.txt' created successfully.\n",
      "Request Failed (request_readme): 404 \n",
      " https://api.github.com/repos/prakhargaming/Lab-thingy/readme\n",
      "File 'github_repos_info\\REPO_INFO_Lab-thingy.txt' created successfully.\n",
      "Request Failed (request_readme): 404 \n",
      " https://api.github.com/repos/prakhargaming/musicdiscordplaylistbot/readme\n",
      "File 'github_repos_info\\REPO_INFO_musicdiscordplaylistbot.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_Neurotech-Davis2022.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_Neurotech_at_Davis_Robotic_Arm.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_ntx22-ui.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_prakhar-website.txt' created successfully.\n",
      "An error occurred: 'charmap' codec can't encode characters in position 276-279: character maps to <undefined>\n",
      "File 'github_repos_info\\REPO_INFO_RAG-Feature-Website.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_scripta-dashboard.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_scripta-dashboard-2.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_scripta-welcome-interface.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_SimCLR_for_Fast_Learning.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_transdeeplab-for-needle-biopsy.txt' created successfully.\n",
      "File 'github_repos_info\\REPO_INFO_u_net-for-needle-biopsy.txt' created successfully.\n",
      "An error occurred: 'charmap' codec can't encode character '\\U0001f4da' in position 996: character maps to <undefined>\n",
      "File 'github_repos_info\\REPO_INFO_vidilab-website.txt' created successfully.\n",
      "Request Failed (request_readme): 404 \n",
      " https://api.github.com/repos/prakhargaming/websocker-react-app/readme\n",
      "File 'github_repos_info\\REPO_INFO_websocker-react-app.txt' created successfully.\n"
     ]
    }
   ],
   "source": [
    "repos = fetch_public_repo_information(GITHUB_USERNAME, generate_embeddings=True, generate_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "563ee221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InsertManyResult([ObjectId('681119164e98ea887be6b50d'), ObjectId('681119164e98ea887be6b50e'), ObjectId('681119164e98ea887be6b50f'), ObjectId('681119164e98ea887be6b510'), ObjectId('681119164e98ea887be6b511'), ObjectId('681119164e98ea887be6b512'), ObjectId('681119164e98ea887be6b513'), ObjectId('681119164e98ea887be6b514'), ObjectId('681119164e98ea887be6b515'), ObjectId('681119164e98ea887be6b516'), ObjectId('681119164e98ea887be6b517'), ObjectId('681119164e98ea887be6b518'), ObjectId('681119164e98ea887be6b519'), ObjectId('681119164e98ea887be6b51a'), ObjectId('681119164e98ea887be6b51b'), ObjectId('681119164e98ea887be6b51c'), ObjectId('681119164e98ea887be6b51d'), ObjectId('681119164e98ea887be6b51e'), ObjectId('681119164e98ea887be6b51f'), ObjectId('681119164e98ea887be6b520'), ObjectId('681119164e98ea887be6b521'), ObjectId('681119164e98ea887be6b522'), ObjectId('681119164e98ea887be6b523')], acknowledged=True)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_database.insert_many(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2e48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index_model = SearchIndexModel(\n",
    "    definition={\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"similarity\": \"cosine\",  # or \"cosine\", depending on your use case\n",
    "                \"numDimensions\": 768         # this must match your embedding model output size\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    name=\"vector_index\",\n",
    "    type=\"vectorSearch\"\n",
    ")\n",
    "\n",
    "vector_database.create_search_index(model=search_index_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
