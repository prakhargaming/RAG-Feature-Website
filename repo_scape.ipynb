{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "18cb480d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e83e8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "GITHUB_USERNAME = \"prakhargaming\"\n",
    "GITHUB_TOKEN = os.getenv(\"REPO\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "    \"Accept\": \"application/vnd.github.v3+json\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1e1c166e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_github_urls(username: str) -> list[str]:\n",
    "    url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    r = requests.get(url, headers=headers)\n",
    "    if r.status_code != 200:\n",
    "        print(r.status_code)\n",
    "        return r.status_code\n",
    "    data = r.json()\n",
    "    url_list = []\n",
    "    for repos in data:\n",
    "        url_list.append({\"repo_name\": repos[\"name\"],\n",
    "                         \"url\": repos[\"url\"],\n",
    "                         \"username\": username})\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "246d59a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_README(url_list: list[dict]) -> list[str]:\n",
    "    readmes = []\n",
    "    for item in url_list:\n",
    "        repo_name = item[\"repo_name\"]\n",
    "        username = item[\"username\"]\n",
    "        url = f\"https://api.github.com/repos/{username}/{repo_name}/contents/README.md\"\n",
    "        url2 = f\"https://api.github.com/repos/{username}/{repo_name}/contents/readme.md\"\n",
    "        r = requests.get(url, headers=headers)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Could not fetch README for {repo_name}: {r.status_code}\")\n",
    "            print(url)\n",
    "            continue\n",
    "        data = r.json()\n",
    "        content = base64.b64decode(data[\"content\"]).decode('utf-8')\n",
    "        readmes.append(content)\n",
    "    return readmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "22e6a0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = fetch_github_urls(\"prakhargaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edf78846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch README for amazonInterview: 404\n",
      "https://api.github.com/repos/prakhargaming/amazonInterview/contents/README.md\n",
      "Could not fetch README for Lab-thingy: 404\n",
      "https://api.github.com/repos/prakhargaming/Lab-thingy/contents/README.md\n",
      "Could not fetch README for musicdiscordplaylistbot: 404\n",
      "https://api.github.com/repos/prakhargaming/musicdiscordplaylistbot/contents/README.md\n",
      "Could not fetch README for vidi-lab-website-basedOnChatApp: 404\n",
      "https://api.github.com/repos/prakhargaming/vidi-lab-website-basedOnChatApp/contents/README.md\n",
      "Could not fetch README for websocker-react-app: 404\n",
      "https://api.github.com/repos/prakhargaming/websocker-react-app/contents/README.md\n"
     ]
    }
   ],
   "source": [
    "READMEs = fetch_README(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc3297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# Data Visualization Web Development Project for VIDI Reseach Lab at UC Davis\\n\\nThis was a data visualization web development project that used a React, SocketIO, Flask/Python tech stack. This was a machine learning adjacent project as well. It was very informative in helping develop web development skills on a consistent deadline. Through development of this web app, I learned a lot of new skills:\\n-   Front end was developed using React, D3 for data visualization, and MUI\\n-\\tCommunication is handled by Socket.io and JSON\\n-\\tBack end was developed using Flask, Python, PyTorch, NumPy, and OpenCV\\n-\\tMachine learning/Data Visualization aspect was visualizing the second to last layer of the ResNet-50 network with the use of forward hooks and TSNE analysis\\n\\nTo run this application, please follow these steps (please note, the data vizualization aspect will not work since the ML waterbirds dataset is not included in this repo):\\n1)  Clone the repo \\n2)  `cd` into the repo and input these commands: \\n    ```bash\\n        python3 -m venv env  \\n        source env/bin/activate  \\n        pip install -r requirements.txt\\n    ```\\n3) `cd` into the front end folder and run these commands: \\n    ```bash\\n        npm i react-scripts\\n    ```\\n4) To run locally, split your terminal. Input these commands at the root of the application in the first terminal window: \\n    ```bash  \\n        cd webSocket-App  \\n        source env/bin/activate  \\n        python3 server.py\\n    ```\\n5) In the second terminal window: \\n    ```bash  \\n        cd webSocket-App/front-end  \\n        npm start\\n    ```\\n\\nHere is a GIF of the web app working in action. \\\\\\n![](/applicationDemo.gif)', '# FastSAM for Needle Biopsy and GigaFIBI with Fereidouni Lab and UC Davis Health\\r\\n\\r\\nThis is a fork of the original [FastSAM model](https://github.com/CASIA-IVA-Lab/FastSAM) developed by the CASIA-IVA-Lab. All credits for their original work go to them. \\r\\n\\r\\nFastSAM for needle biopsy is an image processing pipeline I am developing using FastSAM to quickly generate image segmentation masks from the [GigaFIBI microsope](https://opg.optica.org/abstract.cfm?uri=Microscopy-2024-MS1A.2) and other related projects in the lab. A fastest path is then generated from the mask such that it covers the tissue as quickly and effciently as possible. Here is an example of the mask generated. An example two images are shown below. \\r\\n\\r\\n![pipeline](./images/pipeline3.png)\\r\\n\\r\\n## Installation (currently)\\r\\n\\r\\nAs it stands, I am not sure what is the best way to install this package. As you can see, this is primarily a python package but it is meant to be executed using `C#`. I would like to try to make this a `pip` package in the future but that remains to be seen. For now all you need to do is clone follow these steps:\\r\\n```bash\\r\\ngit clone https://github.com/prakhargaming/FastSAM-needle-biopsy.git\\r\\nconda create -n FastSAM python=3.10\\r\\nconda activate FastSAM\\r\\ncd FastSAM-needle-biopsy\\r\\npip install -r requirements.txt\\r\\nmkdir weights\\r\\ncd weights\\r\\n```\\r\\nDownload [this](https://drive.google.com/file/d/1m1sjY4ihXBU1fZXdQ-Xdj-mDltW-2Rqv/view?pli=1) model checkpoint and put it into the `./weights` directory. Now you can run the scripts below. This repo requires python 3.10. You also need to do some stuff with the required `C#` packages but I am not there yet. You also need some version of the `.NET` sdk. I am not actually sure if this repo is platform agnostic but I am pretending as it is.\\r\\n\\r\\n## Usage (currently)\\r\\n\\r\\n### `./FastSAM_img_segmentation.py`\\r\\n\\r\\nThis program can be run in bash like this\\r\\n```bash\\r\\npython3 FastSAM_img_segmentation.py --model_path ./weights/FastSAM-x.pt --img_path ./tissue --microDims 21,21\\r\\n```\\r\\nThis script can take many arguments. All masks and shortest paths will be saved in the specified directory. Here is the docstring:\\r\\n```\\r\\nParameters:\\r\\n    model_path (str): Path to the model weights file.\\r\\n    img_path (str): Path to the image file or directory containing images.\\r\\n    imgsz (int): Image size for processing.\\r\\n    iou (float): IOU threshold for filtering the annotations.\\r\\n    conf (float): Object confidence threshold.\\r\\n    output (str): Directory to save the segmented images.\\r\\n    point_prompt (str): Points prompt in the format \"[[x1,y1],[x2,y2]]\".\\r\\n    point_label (str): Point labels in the format \"[1,0]\" (0: background, 1: foreground).\\r\\n    box_prompt (str): Box prompt in the format \"[[x,y,w,h],[x2,y2,w2,h2]]\".\\r\\n    better_quality (bool): Flag to use better quality using morphologyEx.\\r\\n    device (str): Device to run the model on (\"cuda\", \"mps\", \"cpu\").\\r\\n    retina (bool): Flag to draw high-resolution segmentation masks.\\r\\n    withContours (bool): Flag to draw the edges of the masks.\\r\\n    microDims (str): Dimensions of image resize for shortest path in the format \"width,height\".\\r\\n    plot (bool): Flag to save and return plot of the results.\\r\\n```\\r\\n### `./csharp/Program.cs`\\r\\n\\r\\nThis will execute the above command but though `C#`. This is mainly for future development.\\r\\n\\r\\n```bash\\r\\ndotnet run\\r\\n```\\r\\n\\r\\n## Miscellaneous\\r\\n\\r\\n### `make clean`\\r\\nMake clean is used to clean to clean the contents of `./output`, the default output directory of `FastSAM_img_segmentation.py`. \\r\\n', '[![Open Source Love](https://firstcontributions.github.io/open-source-badges/badges/open-source-v1/open-source.svg)](https://github.com/firstcontributions/open-source-badges)\\n[<img align=\"right\" width=\"150\" src=\"https://firstcontributions.github.io/assets/Readme/join-slack-team.png\">](https://join.slack.com/t/firstcontributors/shared_invite/zt-vchl8cde-S0KstI_jyCcGEEj7rSTQiA)\\n[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)\\n[![Open Source Helpers](https://www.codetriage.com/roshanjossey/first-contributions/badges/users.svg)](https://www.codetriage.com/roshanjossey/first-contributions)\\n# \\n\\n#### _Read this in [other languages](translations/Translations.md)._\\n\\n<kbd>[<img title=\"Shqip\" alt=\"Shqip\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/al.svg\" width=\"22\">](translations/README.al.md)</kbd>\\n<kbd>[<img title=\"Az…ôrbaycan dili\" alt=\"Az…ôrbaycan dili\" src=\"https://cdn.statically.io/flags/az.svg\" width=\"22\">](translations/README.aze.md)</kbd>\\n<kbd>[<img title=\"‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ\" alt=\"‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/bd.svg\" width=\"22\">](translations/README.bn.md)</kbd>\\n<kbd>[<img title=\"Bulgarian\" alt=\"Bulgarian\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/bg.svg\" width=\"22\">](translations/README.bg.md)</kbd>\\n<kbd>[<img title=\"Portugu√™s\" alt=\"Portugu√™s\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/br.svg\" width=\"22\">](translations/README.pt_br.md)</kbd>\\n<kbd>[<img title=\"Catal√†\" alt=\"Catal√†\" src=\"https://firstcontributions.github.io/assets/Readme/catalan1.png\" width=\"22\">](translations/README.ca.md)</kbd>\\n<kbd>[<img title=\"‰∏≠Êñá (Simplified)\" alt=\"‰∏≠Êñá (Simplified)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/cn.svg\" width=\"22\">](translations/README.chs.md)</kbd>\\n<kbd>[<img title=\"Czech\" alt=\"Czech\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/cz.svg\" width=\"22\">](translations/README.cs.md)</kbd>\\n<kbd>[<img title=\"Deutsch\" alt=\"Deutsch\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/de.svg\" width=\"22\">](translations/README.de.md)</kbd>\\n<kbd>[<img title=\"Dansk\" alt=\"Dansk\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/dk.svg\" width=\"22\">](translations/README.da.md)</kbd>\\n<kbd>[<img title=\"ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\" alt=\"ÿßŸÑÿπÿ±ÿ®Ÿäÿ©\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/eg.svg\" width=\"22\">](translations/README.eg.md)</kbd>\\n<kbd>[<img title=\"Espa√±ola\" alt=\"Espa√±ola\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/es.svg\" width=\"22\">](translations/README.es.md)</kbd>\\n<kbd>[<img title=\"Fran√ßaise\" alt=\"Fran√ßaise\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/fr.svg\" width=\"22\">](translations/README.fr.md)</kbd>\\n<kbd>[<img title=\"Galego\" alt=\"Galego\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Flag_of_Galicia.svg/1200px-Flag_of_Galicia.svg.png\" width=\"22\">](translations/README.gl.md)</kbd>\\n<kbd>[<img title=\"ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\" alt=\"ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/gr.svg\" width=\"22\">](translations/README.gr.md)</kbd>\\n<kbd>[<img title=\"·É•·Éê·É†·Éó·É£·Éö·Éò\" alt=\"·É•·Éê·É†·Éó·É£·Éö·Éò\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ge.svg\" width=\"22\">](translations/README.ge.md)</kbd>\\n<kbd>[<img title=\"Magyar\" alt=\"Magyar\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/hu.svg\" width=\"22\">](translations/README.hu.md)</kbd>\\n<kbd>[<img title=\"Bahasa Indonesia\" alt=\"Bahasa Indonesia\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/id.svg\" width=\"22\">](translations/README.id.md)</kbd>\\n<kbd>[<img title=\"◊¢÷¥◊ë◊®÷¥◊ô◊™\" alt=\"◊¢÷¥◊ë◊®÷¥◊ô◊™\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/il.svg\" width=\"22\">](translations/README.hb.md)</kbd>\\n<kbd>[<img title=\"‡§π‡§ø‡§Ç‡§¶‡•Ä/‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä/‡§Æ‡§∞‡§æ‡§†‡•Ä/‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç/‡≤ï‡≤®‡≥ç‡≤®‡≤°/‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å/‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡§¢‡§º‡•Ä/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ/‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç\" alt=\"‡§π‡§ø‡§Ç‡§¶‡•Ä/‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä/‡§Æ‡§∞‡§æ‡§†‡•Ä/‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç/‡≤ï‡≤®‡≥ç‡≤®‡≤°/‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å/‡§õ‡§§‡•ç‡§§‡•Ä‡§∏‡§ó‡§¢‡§º‡•Ä/‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ/‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/in.svg\" width=\"22\">](translations/Translations.md)</kbd>\\n<kbd>[<img title=\"‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç\" alt=\"‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/lk.svg\" width=\"22\">](translations/README.ta.md)</kbd>\\n<kbd>[<img title=\"ŸÅÿßÿ±ÿ≥€å\" alt=\"ŸÅÿßÿ±ÿ≥€å\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ir.svg\" width=\"22\">](translations/README.fa.md)</kbd>\\n<kbd>[<img title=\"Italiano\" alt=\"Italiano\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/it.svg\" width=\"22\">](translations/README.it.md)</kbd>\\n<kbd>[<img title=\"Êó•Êú¨Ë™û\" alt=\"Êó•Êú¨Ë™û\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/jp.svg\" width=\"22\">](translations/README.ja.md)</kbd>\\n<kbd>[<img title=\"Kiswahili (Kenya)\" alt=\"Kiswahili (Kenya)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ke.svg\" width=\"22\">](translations/README.kws.md)</kbd>\\n<kbd>[<img title=\"ÌïúÍµ≠Ïñ¥\" alt=\"ÌïúÍµ≠Ïñ¥\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/kr.svg\" width=\"22\"> <img title=\"ÌïúÍµ≠Ïñ¥\" alt=\"ÌïúÍµ≠Ïñ¥\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/kp.svg\" width=\"22\">](translations/README.ko.md)</kbd>\\n<kbd>[<img title=\"Lietuvi≈≥ kalba\" alt=\"Lietuvi≈≥ kalba\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/lt.svg\" width=\"22\">](translations/README.lt.md)</kbd>\\n<kbd>[<img title=\"Limba Rom√¢nƒÉ\" alt=\"Limba Rom√¢nƒÉ\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/md.svg\" width=\"22\"> <img title=\"Limba Rom√¢nƒÉ\" alt=\"Limba Rom√¢nƒÉ\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ro.svg\" width=\"22\">](translations/README.ro.md)</kbd>\\n<kbd>[<img title=\"·Äô·Äº·Äî·Ä∫·Äô·Ä¨\" alt=\"·Äô·Äº·Äî·Ä∫·Äô·Ä¨\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/mm.svg\" width=\"22\">](translations/README.mm_unicode.md)</kbd>\\n<kbd>[<img title=\"–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏\" alt=\"–ú–∞–∫–µ–¥–æ–Ω—Å–∫–∏\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/mk.svg\" width=\"22\">](translations/README.mk.md)</kbd>\\n<kbd>[<img title=\"Espa√±ol de M√©xico\" alt=\"Espa√±ol de M√©xico\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/mx.svg\" width=\"22\">](translations/README.mx.md)</kbd>\\n<kbd>[<img title=\"Bahasa Melayu / ÿ®Ÿáÿßÿ≥ ŸÖŸÑÿßŸäŸà\\u200e / Malay\" alt=\"Bahasa Melayu / ÿ®Ÿáÿßÿ≥ ŸÖŸÑÿßŸäŸà\\u200e / Malay\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/my.svg\" width=\"22\">](translations/README.my.md)</kbd>\\n<kbd>[<img title=\"Dutch\" alt=\"Dutch\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/nl.svg\" width=\"22\">](translations/README.nl.md)</kbd>\\n<kbd>[<img title=\"Norsk\" alt=\"Norsk\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/no.svg\" width=\"22\">](translations/README.no.md)</kbd>\\n<kbd>[<img title=\"‡§®‡•á‡§™‡§æ‡§≤‡•Ä\" alt=\"‡§®‡•á‡§™‡§æ‡§≤‡•Ä\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/np.svg\" width=\"15\">](translations/README.np.md)</kbd>\\n<kbd>[<img title=\"Wikang Filipino\" alt=\"Wikang Filipino\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ph.svg\" width=\"22\">](translations/README.tl.md)</kbd>\\n<kbd>[<img title=\"English (Pirate)\" alt=\"English (Pirate)\" src=\"https://firstcontributions.github.io/assets/Readme/pirate.png\" width=\"22\">](translations/README.en-pirate.md)</kbd>\\n<kbd>[<img title=\"ÿßŸèÿßÿ±ÿØŸà\" alt=\"ÿßÿ±ÿØŸà\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/pk.svg\" width=\"22\">](translations/README.ur.md)</kbd>\\n<kbd>[<img title=\"Polski\" alt=\"Polski\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/pl.svg\" width=\"22\">](translations/README.pl.md)</kbd>\\n<kbd>[<img title=\"Portugu√™s (Portugal)\" alt=\"Portugu√™s (Portugal)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/pt.svg\" width=\"22\">](translations/README.pt-pt.md)</kbd>\\n<kbd>[<img title=\"–†—É—Å—Å–∫–∏–π —è–∑—ã–∫\" alt=\"–†—É—Å—Å–∫–∏–π —è–∑—ã–∫\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ru.svg\" width=\"22\">](translations/README.ru.md)</kbd>\\n<kbd>[<img title=\"ÿπÿ±ÿ®Ÿâ\" alt=\"ÿπÿ±ÿ®Ÿâ\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/sa.svg\" width=\"22\">](translations/README.ar.md)</kbd>\\n<kbd>[<img title=\"Svenska\" alt=\"Svenska\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/se.svg\" width=\"22\">](translations/README.se.md)</kbd>\\n<kbd>[<img title=\"Slovenƒçina\" alt=\"Slovenƒçina\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/sk.svg\" width=\"22\">](translations/README.slk.md)</kbd>\\n<kbd>[<img title=\"Sloven≈°ƒçina\" alt=\"Sloven≈°ƒçina\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/si.svg\" width=\"22\">](translations/README.sl.md)</kbd>\\n<kbd>[<img title=\"‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\" alt=\"‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/th.svg\" width=\"22\">](translations/README.th.md)</kbd>\\n<kbd>[<img title=\"T√ºrk√ße\" alt=\"T√ºrk√ße\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/tr.svg\" width=\"22\">](translations/README.tr.md)</kbd>\\n<kbd>[<img title=\"‰∏≠Êñá(Traditional)\" alt=\"‰∏≠Êñá(Traditional)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/tw.svg\" width=\"22\">](translations/README.cht.md)</kbd>\\n<kbd>[<img title=\"–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞\" alt=\"–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ua.svg\" width=\"22\">](translations/README.ua.md)</kbd>\\n<kbd>[<img title=\"Ti·∫øng Vi·ªát\" alt=\"Ti·∫øng Vi·ªát\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/vn.svg\" width=\"22\">](translations/README.vn.md)</kbd>\\n<kbd>[<img title=\"Zulu (South Africa)\" alt=\"Zulu (South Africa)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/za.svg\" width=\"22\">](translations/README.zul.md)</kbd>\\n<kbd>[<img title=\"Afrikaans (South Africa)\" alt=\"Afrikaans (South Africa)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/za.svg\" width=\"22\">](translations/README.afk.md)</kbd>\\n<kbd>[<img title=\"Igbo (Nigeria)\" alt=\"Igbo (Nigeria)\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ng.svg\" width=\"22\">](translations/README.igb.md)</kbd>\\n<kbd>[<img title=\"Latvia\" alt=\"Latvia\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/lv.svg\" width=\"22\">](translations/README.lv.md)</kbd>\\n<kbd>[<img title=\"Suomeksi\" alt=\"Suomeksi\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/fi.svg\" width=\"22\">](translations/README.fi.md)</kbd>\\n<kbd>[<img title=\"–ë–µ–ª–∞—Ä—É—Å–∫–∞—è –º–æ–≤–∞\" alt=\"–ë–µ–ª–∞—Ä—É—Å–∫–∞—è –º–æ–≤–∞\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/by.svg\" width=\"22\">](translations/README.by.md)</kbd>\\n<kbd>[<img title=\"–°—Ä–ø—Å–∫–∏\" alt=\"–°—Ä–ø—Å–∫–∏\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/rs.svg\" width=\"22\">](translations/README.sr.md)</kbd>\\n<kbd>[<img title=\"“ö–∞–∑–∞“õ—à–∞\" alt=\"“ö–∞–∑–∞“õ—à–∞\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/kz.svg\" width=\"22\">](translations/README.kz.md)</kbd>\\n<kbd>[<img title=\"Bosanski\" alt=\"Bosanski\" src=\"https://cdn.staticaly.com/gh/hjnilsson/country-flags/master/svg/ba.svg\" width=\"22\">](translations/README.bih.md)</kbd>\\n# \\n\\n# First Contributions\\n\\nThis project aims to simplify and guide the way beginners make their first contribution. If you are looking to make your first contribution, follow the steps below.\\n\\n_If you\\'re not comfortable with command line, [here are tutorials using GUI tools.](#tutorials-using-other-tools)_\\n\\n<img align=\"right\" width=\"300\" src=\"https://firstcontributions.github.io/assets/Readme/fork.png\" alt=\"fork this repository\" />\\n\\n#### If you don\\'t have git on your machine, [install it](https://help.github.com/articles/set-up-git/).\\n\\n## Fork this repository\\n\\nFork this repository by clicking on the fork button on the top of this page.\\nThis will create a copy of this repository in your account.\\n\\n## Clone the repository\\n\\n<img align=\"right\" width=\"300\" src=\"https://firstcontributions.github.io/assets/Readme/clone.png\" alt=\"clone this repository\" />\\n\\nNow clone the forked repository to your machine. Go to your GitHub account, open the forked repository, click on the code button and then click the _copy to clipboard_ icon.\\n\\nOpen a terminal and run the following git command:\\n\\n```\\ngit clone \"url you just copied\"\\n```\\n\\nwhere \"url you just copied\" (without the quotation marks) is the url to this repository (your fork of this project). See the previous steps to obtain the url.\\n\\n<img align=\"right\" width=\"300\" src=\"https://firstcontributions.github.io/assets/Readme/copy-to-clipboard.png\" alt=\"copy URL to clipboard\" />\\n\\nFor example:\\n\\n```\\ngit clone https://github.com/this-is-you/first-contributions.git\\n```\\n\\nwhere `this-is-you` is your GitHub username. Here you\\'re copying the contents of the first-contributions repository on GitHub to your computer.\\n\\n## Create a branch\\n\\nChange to the repository directory on your computer (if you are not already there):\\n\\n```\\ncd first-contributions\\n```\\n\\nNow create a branch using the `git checkout` command:\\n\\n```\\ngit checkout -b your-new-branch-name\\n```\\n\\nFor example:\\n\\n```\\ngit checkout -b add-alonzo-church\\n```\\n\\n(The name of the branch does not need to have the word _add_ in it, but it\\'s a reasonable thing to include because the purpose of this branch is to add your name to a list.)\\n\\n## Make necessary changes and commit those changes\\n\\nNow open `Contributors.md` file in a text editor, add your name to it. Don\\'t add it at the beginning or end of the file. Put it anywhere in between. Now, save the file.\\n\\n<img align=\"right\" width=\"450\" src=\"https://firstcontributions.github.io/assets/Readme/git-status.png\" alt=\"git status\" />\\n\\nIf you go to the project directory and execute the command `git status`, you\\'ll see there are changes.\\n\\nAdd those changes to the branch you just created using the `git add` command:\\n\\n```\\ngit add Contributors.md\\n```\\n\\nNow commit those changes using the `git commit` command:\\n\\n```\\ngit commit -m \"Add <your-name> to Contributors list\"\\n```\\n\\nreplacing `<your-name>` with your name.\\n\\n## Push changes to GitHub\\n\\nPush your changes using the command `git push`:\\n\\n```\\ngit push origin <add-your-branch-name>\\n```\\n\\nreplacing `<add-your-branch-name>` with the name of the branch you created earlier.\\n\\n## Submit your changes for review\\n\\nIf you go to your repository on GitHub, you\\'ll see a `Compare & pull request` button. Click on that button.\\n\\n<img style=\"float: right;\" src=\"https://firstcontributions.github.io/assets/Readme/compare-and-pull.png\" alt=\"create a pull request\" />\\n\\nNow submit the pull request.\\n\\n<img style=\"float: right;\" src=\"https://firstcontributions.github.io/assets/Readme/submit-pull-request.png\" alt=\"submit pull request\" />\\n\\nSoon I\\'ll be merging all your changes into the master branch of this project. You will get a notification email once the changes have been merged.\\n\\n## Where to go from here?\\n\\nCongrats! You just completed the standard _fork -> clone -> edit -> pull request_ workflow that you\\'ll encounter often as a contributor!\\n\\nCelebrate your contribution and share it with your friends and followers by going to [web app](https://firstcontributions.github.io/#social-share).\\n\\nYou could join our slack team in case you need any help or have any questions. [Join slack team](https://join.slack.com/t/firstcontributors/shared_invite/zt-vchl8cde-S0KstI_jyCcGEEj7rSTQiA).\\n\\nNow let\\'s get you started with contributing to other projects. We\\'ve compiled a list of projects with easy issues you can get started on. Check out [the list of projects in the web app](https://firstcontributions.github.io/#project-list).\\n\\n### [Additional material](additional-material/git_workflow_scenarios/additional-material.md)\\n\\n## Tutorials Using Other Tools\\n\\n| <a href=\"gui-tool-tutorials/github-desktop-tutorial.md\"><img alt=\"GitHub Desktop\" src=\"https://desktop.github.com/images/desktop-icon.svg\" width=\"100\"></a> | <a href=\"gui-tool-tutorials/github-windows-vs2017-tutorial.md\"><img alt=\"Visual Studio 2017\" src=\"https://upload.wikimedia.org/wikipedia/commons/c/cd/Visual_Studio_2017_Logo.svg\" width=\"100\"></a> | <a href=\"gui-tool-tutorials/gitkraken-tutorial.md\"><img alt=\"GitKraken\" src=\"https://firstcontributions.github.io/assets/gui-tool-tutorials/gitkraken-tutorial/gk-icon.png\" width=\"100\"></a> | <a href=\"gui-tool-tutorials/github-windows-vs-code-tutorial.md\"><img alt=\"VS Code\" src=\"https://upload.wikimedia.org/wikipedia/commons/2/2d/Visual_Studio_Code_1.18_icon.svg\" width=100></a> | <a href=\"gui-tool-tutorials/sourcetree-macos-tutorial.md\"><img alt=\"Sourcetree App\" src=\"https://wac-cdn.atlassian.com/dam/jcr:81b15cde-be2e-4f4a-8af7-9436f4a1b431/Sourcetree-icon-blue.svg\" width=100></a> | <a href=\"gui-tool-tutorials/github-windows-intellij-tutorial.md\"><img alt=\"IntelliJ IDEA\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/9c/IntelliJ_IDEA_Icon.svg/512px-IntelliJ_IDEA_Icon.svg.png\" width=100></a> |\\n| ----------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\\n| [GitHub Desktop](gui-tool-tutorials/github-desktop-tutorial.md)                                                                                             | [Visual Studio 2017](gui-tool-tutorials/github-windows-vs2017-tutorial.md)                                                                                                                          | [GitKraken](gui-tool-tutorials/gitkraken-tutorial.md)                                                                                                                                        | [Visual Studio Code](gui-tool-tutorials/github-windows-vs-code-tutorial.md)                                                                                                                  | [Atlassian Sourcetree](gui-tool-tutorials/sourcetree-macos-tutorial.md)                                                                                                                                      | [IntelliJ IDEA](gui-tool-tutorials/github-windows-intellij-tutorial.md)                                                                                                                                                          |\\n', '# Flask-React Docker Template\\n\\nThis project is a web app built with Python backend and ReactJS frontend to be used as a starter template.\\n\\n## Built With\\n\\n* [Python 3](https://www.python.org/)\\n* [Flask](http://flask.pocoo.org/)\\n* [React](https://reactjs.org/)\\n* [Docker](https://www.docker.com/)\\n\\n## Prerequisites\\n\\nYou will need the following things properly installed on your computer:\\n\\n* [Git](http://git-scm.com/)\\n* [Python 3](https://www.python.org/)\\n* [React](https://reactjs.org/)\\n* [Docker](https://www.docker.com/)\\n\\n## Installation\\n\\n* run `git clone https://github.com/caseyr003/flask-react-template.git`\\n\\n## Running\\n\\nTo run the project locally follow the following steps:\\n\\n* change into the project directory\\n* `docker-compose up`\\n\\n## Backend\\n\\nFlask for the backend API (default port `5000`)\\nFor more information see the README.md file in the backend directory\\n\\n## Frontend\\n\\nReact for the frontend (default port `3000`)\\nFor more information see the README.md file in the frontend directory\\n\\n## License\\n\\nThis project is licensed under the MIT License\\n', \"# GenAI Powered Smart Categorization Engine\\nDeveloped by Prakhar Sinha\\n\\n## Introduction/Description\\nThis is a full-stack web application designed to ingest the following data as structured JSON data:\\n1. **Product Title**\\n2. **Product Description**\\n3. **Associated Search Results** \\n\\nThe engine will then output the search results that are actually relevant to the product title and description using GenAI and natural language processing (NLP).\\n\\n## Data Processing Pipeline\\nData is processed in a multistage pipeline:\\n1. JSON data is loaded into the system\\n2. Data is preprocessed according to standard NLP principles\\n3. Embeddings are generated\\n4. Heuristics are applied\\n5. Heuristics are cross-validated by an LLM\\n\\n### Data Preprocessing\\nThe data that is uploaded undergoes extensive preprocessing to make it ready for the embedding. Text is standarized by a combination of lowercasing, removing special characters, stopwords, and lemmatizing.\\n\\n### Embeddings\\nEmbeddings are generated from preprocessed data by one of two models:\\n1. **OpenAI text-embedding-3-small** This is the standard model and provides the best results\\n2. **Sentence Transformer all-MiniLM-L6-v2** This model is used if there are no OpenAI tokens available to use\\n\\n### Heuristics\\nThe main heuristic applied is **Cosine Similarity** where each search result is compared to its corresponding product title and description. This works very well most of the time and made me question the need to incorporate GenAI,\\n\\n### LLM/GenAI Cross-Validation\\nFinally, the search results are cross-validated by an LLM. I originally opted to go for GPT-4 but after testing this is felt overkill. I ended up using a lighter model, GPT-4o Mini, with mixed results. \\n\\n## Full-Stack Application\\nAlthough only the development of a GenAI pipeline was asked in the project description, I opted to go the extra mile and design a full stack application around the pipeline as well.\\n\\n### Tech Stack\\nThese are the technologies I used in the development of this project\\n\\n- **Frontend**\\n  - Next.js\\n  - TypeScript\\n  - Tailwind CSS\\n- **Backend**\\n  - Python\\n  - Flask\\n- **Communication**\\n  - Socket.io\\n  - JSON\\n\\n## Known Bugs\\n- The first and most noticeable bug is that you must refresh the frontend webpage whenever you want to upload a new JSON file. I'm working on fixing this.\\n\\n## Getting Started\\nThere is a helpful bash script to help you run this script locally. You will need to make an `.env` file with an OpenAI key in the `./backend/app/engine` directory to get started. After this is done, installation should be straight forward. Run this command in your terminal to begin.\\n\\n```sh\\n~ ./run.sh  \\n```\\n\", '# Neurotech-Davis2022\\n\\nhi lol\\n', '# Neurotech@Davis Robotic Arm Project\\n## Developers\\n', '# Neurotech@UCD\\nThis repo contains all of the wireframes for the GUI for the 2022 Neurotech hackathon\\n', 'This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\\n\\n## Getting Started\\n\\nFirst, run the development server:\\n\\n```bash\\nnpm run dev\\n# or\\nyarn dev\\n# or\\npnpm dev\\n# or\\nbun dev\\n```\\n\\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\\n\\nYou can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.\\n\\nThis project uses [`next/font`](https://nextjs.org/docs/basic-features/font-optimization) to automatically optimize and load Inter, a custom Google Font.\\n\\n## Learn More\\n\\nTo learn more about Next.js, take a look at the following resources:\\n\\n- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.\\n- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.\\n\\nYou can check out [the Next.js GitHub repository](https://github.com/vercel/next.js/) - your feedback and contributions are welcome!\\n\\n## Deploy on Vercel\\n\\nThe easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.\\n\\nCheck out our [Next.js deployment documentation](https://nextjs.org/docs/deployment) for more details.\\n', \"## Hi Everyone üôã\\u200d‚ôÇÔ∏è\\n\\nMy name is Prakhar Sinha. I am an aspiring software developer! I recently graduated from UC Davis and am looking to break into the software industry. A little bit about myself is that I love nature, traveling and going on hikes! However, when I'm inside, you can find me either reading a book, playing a video game or drawing. When it comes to CS, I have three key areas of focus.\\n\\n## ü§ñ **AI/Computer Vision** \\nI really like messing around with AI Models! I have a lot of experience here. My main area of interest in the field is **eXplainable AI (XAI)** and **Computer Vision**. Refer to these projects if you'd like to see what I've done in these areas!\\n- [FastSAM for Needle Biopsy:](https://github.com/prakhargaming/FastSAM-needle-biopsy) This is what I'm currently working on for UC Davis Health and Dr. Fereidouni's lab. I'm using the FastSAM model (originally developed by Meta Research) to develop an automated imaging processing pipeline for the [GigaFIBI microscope](https://opg.optica.org/abstract.cfm?uri=Microscopy-2024-MS1A.2).\\n- [XAI ResNet-50 Data Visualization Web Development Project:](https://github.com/prakhargaming/Data-Visualization-Web-Dev-Project) My task with this project was to visualize the second to last layer of the ResNet-50 machine-learning model to help us better understand why the model came to the designs it did.\\n\\n## üï∏ **Front-End Web Development** \\nI used to fear front-end development but now over half my commit history has to do with TypeScript üò®. I've grown to like it quite a bit! These days I'm usually working with NextJS, TypeScript and Tailwind.\\n- [Scripta Welcome Page:](https://github.com/prakhargaming/scripta-welcome-interface) This is what I'm currently working on as well! This is being developed for the company I intern at, VDart. I think it showcases my front-end skills the best. This web app prompts the user to record audio, works with AWS and DigitalOcean to send and receive data, uses Firebase for authentication and contains some of my most sophisticated front-end code to date.\\n- [Scripta Dashboard:](https://github.com/prakhargaming/scripta-dashboard) This repo follows the same story as the previous one. Cool things about this web app is that it uses TailwindUI for stylization (so it looks really nice), Firebase for authentication and dynamically renders tables with data from DigitalOcean.\\n  \\n## üß† **Brain-Computer Interfaces** \\nThis was my labor of love in college. I was the co-head of the Neurotech@Davis projects division for 2 years. I will always look fondly on my days developing brain computer interfaces in the future and I hope to one day go back to them in the industry.\\n- [Neuro-Prosthetic EEG Controlled Robotic Arm:](https://github.com/Neurotech-Davis/RoboticArm) I think this is the coolest thing I've ever made. This project used the mental imagery of a real person to move a prosthetic arm.\\n- [Chrome No Internet Game Using EEG](https://github.com/Neurotech-Davis/Neurofest-Project-2023) This was one of my first BCI projects. It used EEG signals to control the dinosaur in the famous chrome no-internet game.\\n\", '# RAG Enabled Chatbot for [prakhargaming.com](https://www.prakhargaming.com)\\n\\nThis is the prototype/testing repo for the feature. It will be integrated into the main repo soon.', '# Scripta Dashboard\\n![CreateNextApp-GoogleChrome2024-07-2512-32-32-ezgif com-video-to-gif-converter](https://github.com/user-attachments/assets/184d922f-acec-4d45-9380-3e3d4b7ddda6)\\n', 'This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\\n\\n## Getting Started\\n\\nFirst, run the development server:\\n\\n```bash\\nnpm run dev\\n```\\n\\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\\n\\n## Different Pages and Figma\\nThis is the [link](https://www.figma.com/design/4TTKiZBWNj3BVHnpH7McFs/VDart-Figma?node-id=1439-126&t=E4HT0VewWMuu1kLp-0) to the Figma design. The design, at the moment, is all contained within the `./src/app/page.tsx` file. ', \"This is a [Next.js](https://nextjs.org/) project bootstrapped with [`create-next-app`](https://github.com/vercel/next.js/tree/canary/packages/create-next-app).\\n\\n## Getting Started\\n\\nFirst, run the development server:\\n\\n```bash\\nnpm run dev\\n```\\n\\nOpen [http://localhost:3000](http://localhost:3000) with your browser to see the result.\\n\\n## Different Pages and Figma\\nThis is the [link](https://www.figma.com/design/4TTKiZBWNj3BVHnpH7McFs/VDart-Figma?node-id=1439-126&t=E4HT0VewWMuu1kLp-0) to the Figma design. All .tsx pages can be found in the `./src/pages` directory. Every `[name].tsx` page in the `./src/pages` directory corresponds to it's respective page in the Figma design. I am still working on stylization fixes and as well as generally optimizing the code.\", '# SimCLR for Fast Learning\\nBy Prakhar Sinha\\n\\n## Introduction\\n*SimCLR for Fast Learning* is a fine-tuned version of the original [*PyTorch SimCLR: A Simple Framework for Contrastive Learning of Visual Representations*](https://github.com/sthalles/SimCLR) model trained on the firefighting device detection dataset on [Roboflow](firefighting-device-detection/). \\n\\n## Evaluation\\n<p align=\"middle\">\\n  <img src=\"README_images/train.png\" width=\"45%\" />\\n  <img src=\"README_images/test.png\" width=\"45%\" /> \\n</p>\\n\\nThe final accuracy of the model on the test dataset was $\\\\approx 0.8$. TSNE analysis was used to visualize the embedding space.\\n\\n## Hardware/Enviornment\\nThis model was trained on the ASUS Zephyrus G14 GA401IV notebook running Windows 11, equipped with a AMD Ryzen 9 4900HS processor and RTX 2060 Max-Q (6 GB vRAM) graphics card in 8 minutes. \\n\\n## Instructions\\n1. Open the terminal and run install all the neccessary libraries \\n   ```bash\\n   pip install -r requirements.txt\\n   ```\\n2. Download the [Roboflow dataset](https://universe.roboflow.com/ds/mPFMlmd3O4?key=7Z5xZILK4P). in YOLOv11 format. Put the dataset in the `./datasets` folder. These folders should now exist: `./datasets/test`, `./datasets/train`, and `./datasets/valid`\\n3. Run `python3 Symbol_Extraction.py`. This was extract all the symbols from the dataset and put them in a new folder called `./datasets_extracted_symbols`.\\n4. Run all the cells in `./SimCLR.ipynb`\\n\\n## Summary of Changes and Fine-Tuning\\n### `./Symbol_Extraction.py`\\nThis is a script that was created for this project. It reads the YOLOv11 annotations and extracts all the symbols from the dataset.\\n\\n### `./data_aug/contrastive_learning_dataset.py`\\nThe original classes were heavily modifed for the purposes for this project. They are now specialized to load in the symbols from `Symbol_Extraction.py`\\n\\n### Fine-Tuning and SimCLR Modifications\\n#### Hyperparameters\\nThis is the list of the hyperparameters that were used for this project\\n```py\\nbatch_size = 512  \\nepochs = 30      \\nlearning_rate = 0.001  \\ntemperature = 0.1  \\ndevice = \\'cuda\\' if torch.cuda.is_available() else \\'cpu\\'\\nn_views = 2      \\nout_dim = 16     \\ndisable_cuda = False\\nfp16_precision = True  \\nlog_every_n_steps = 25 \\narch = \\'resnet18\\'\\nnum_workers = 4 \\nweight_decay = 2e-4\\n```\\n- `batch_size` Batch size was adjusted for 512 based on vRAM limitations.\\n- `epochs` On average, it took 7 minutes to train the model for 30 epochs, which I felt was reasonable.\\n- `learning_rate` I didn\\'t mess around with the learning rate too much. It is lower than usual to accomodate for time constraints.\\n- `n_views` The base model of SimCLR only supports 2 views to my knowledge.\\n- `out_dim` I kept this very small because the symbols themselves were, at most, 30x30 pixels.\\n- `arch` I chose `resnet18` because it was included with the base model. In the future, I might try a smaller version of resnet to see if that would effect anything.\\n- `weight_decay` This was set to $2e^{-4}$ because of the time constraints associated with this project.\\n\\n#### SimCLR modifications\\nI modified the SimCLR image transformation pipeline a signifcant amount because I wanted to specialize it to the task at hand. This is a list of transformations. This can be found in `./data_aug/contrastive_learning_dataset.py`:\\n```py\\ndef get_simclr_pipeline_transform(size, s=1):\\n    \"\"\"Return a set of data augmentation transformations as described in the SimCLR paper.\"\"\"\\n    data_transforms = transforms.Compose([\\n        transforms.RandomResizedCrop(size=size),\\n        transforms.RandomHorizontalFlip(),\\n        transforms.RandomGrayscale(p=0.2),\\n        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),\\n        transforms.ToTensor()\\n    ])\\n    return data_transforms\\n```\\n- `color_jitter` was removed entirely. Based on the nature of the symbols we were working with, I hypotheosized that adding color jitter to the transformations was unnessessary.\\n- `gaussian_blur` was also removed. Blurring such a small image didn\\'t seem to add anything and I thought it was confounding the model.\\n- `RandomAffine` was added. I though introducing pixel level shifts might improve the robustness of the model.\\n\\nThe rest of thr transforms are apart of the standard SimCLR pipeline.\\n\\n## Use of Generative AI\\nMethods for data visualization, towards the end of the Jupyter Notebook, were generated using Claude 3.5 Sonnet.\\n', '# TransDeepLab For Needle Biopsy Image Segmentation\\n\\n(THIS IS A FORK OF THE ORIGINAL [TRANSDEEPLAB REPOSITORY](https://github.com/rezazad68/transdeeplab), ALL CREDITS GO TO THEM FOR THEIR ORIGINAL IMPLEMENTATION)\\n\\n## Few notes about usage:\\n\\n### `runImageThroughModel.py`\\n\\nThis python script produces an image segmentation mask with the trained ML model based on an image that you feed into it. This is how you use the script:\\n```bash\\npython3 script.py --image_path \"mask_generation/fun_images/217613113.png\"\\n```\\n\\n### `mask_maker_script.py`\\n\\nThis python script produces masks based on a given annotation file. This is how you use it:\\n```bash \\npython script_name.py --image_dir \"./mask_generation/fun_images\" --annotation_file \"./mask_generation/annotations1.csv\" --mask_dir ./\"mask_generation/masks\"\\n``` \\nThe only required argument is the annotation file. ', '# u_net-for-needle-biopsy', '### VIDI-LAB Website\\n\\nWIP']\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
